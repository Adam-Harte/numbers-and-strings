<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="UTF-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1.0" />
		<script src="app.js"></script>
		<title>Numbers and Strings</title>
	</head>
	<body>
		<h1>Number and Strings</h1>
		<h3>Number</h3>
		<p>
			All numbers in JavaScript are technically floating point numbers even if
			you deifne them as integers. Specifically they are 64 bit floating point
			values meaning there is 64 bites set to represent the value 1 bit for the
			positive or negative sign and the rest for the number and decimal place
			digits. Due to the 64 bit size there is a limit to the size of the number
			you can define which you can see via the Number object which can give you
			access to the max and min numbers and values.
		</p>
		<h3>Floating Point Precision</h3>
		<p>
			JavaScript represents numbers/floats in a binary systme even though we
			define them in a decimal system and this binary system implemenets
			rounding whihc can sometimed give us odd and unexpetced results e.g. 0.2 +
			0.4 does not equal 0.6 in the binary system. We have ways to get the
			correct precision such as using the toFixed method which converts the
			floating point to a string of the number down to the amount of decimal
			places ypu pass as an argument to toFixed. Another method is to multiply
			the number by 100 so that you are always working with integer values and
			therfore avoid the floating point precision problem altogether.
		</p>
	</body>
</html>
